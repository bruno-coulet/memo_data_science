retranscription des livres :
- Python pour la data science, √©ditions ENI, page 198
- [Python pour le data scientist](https://github.com/bruno-coulet/pythondatascientist), √©ditions Dunod
## intro
Importer la librairie :
 ```python
import pandas as pd
```

| ligne   | <font color="orange">individus</font>  ou <font color="orange">observation</font><br> |
| ------- | ------------------------------------------------------------------------------------- |
| colonne | <font color="orange">variables</font> ou <font color="orange">champs</font>           |
 ¬†**Librairie** python qui s'appuie sur [[Numpy]] et apporte 2 structures essentielles pour l'analyse de donn√©es :

| Structures de donn√©e :  |                                                                                                                                                                                       |                           |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| [DataFrame](#DataFrame) | peut √™tre assimil√© √† un tableau 2 dimensions<br>est constitu√© d'autant de `Series` qu'il a de colonnes                                                                                | par d√©faut                |
|                         | - structure sous forme de tableau<br>- chaque colonne √† des √©l√©ments de m√™me type<br>- index√© par des ``index`` pour les lignes<br>- index√© par des ``columns`` pour les colonnes<br> |                           |
| [Series](#Series)       | peut √™tre assimil√© √† un vecteur<br>suite de valeurs stock√©es dans une colonne et index√©es<br>                                                                                         | option `squeeze=True`<br> |
|                         |                                                                                                                                                                                       |                           |
- un ensemble de m√©thodes et de fonctions associ√©es pour
	- explorer les dataframes et series
	- les nettoyer 
	- les transformer 
	- les manipuler
	- les visualiser
- permet de stocker des donn√©es de types diff√©rents (un par s√©rie / colonne)
- possibilit√© d'assigner une √©tiquette aux donn√©es plut√¥t qu'un index num√©rique
- manipule efficacement les donn√©es manquantes
- manipule efficacement les donn√©es de s√©rie temporelles (time series data)
- lit les donn√©es provenant de diff√©rentes sources, des fichiers d√©limit√©s (CSV ou texte), ou encore des fichiers JSON ou Excel.
---
---
## Types

Il faut un seul type par colonne

### 3 types principaux :
- entiers  :      `Int8`, `Int16`, `Int32`, `Int64`. Peut g√©rer des valeurs manquantes (`NaN`)
- d√©cimaux :   `float32` ou `float64`
- autres types : `object`

### types courants dans Pandas :

| Type        | Exemple Pandas                    | Description                          |
| ----------- | --------------------------------- | ------------------------------------ |
| `int`       | `Int8`, `Int16`, `Int32`, `Int64` | Nombres entiers (avec ou sans `NaN`) |
| `float`     | `float64`                         | Nombres r√©els                        |
| `bool`      | `boolean`                         | Bool√©ens (avec ou sans `NaN`)        |
| `object`    | `object`                          | Cha√Ænes de caract√®res ou objets      |
| `string`    | `string`                          | Cha√Ænes de caract√®res (natif)        |
| `datetime`  | `datetime64[ns]`                  | Dates et heures                      |
| `timedelta` | `timedelta64[ns]`                 | Dur√©es                               |
| `category`  | `category`                        | Donn√©es cat√©goriques                 |
| `period`    | `Period`                          | P√©riodes de temps                    |
| `interval`  | `Interval`                        | Intervalles                          |

Ces types permettent une manipulation efficace des donn√©es selon leur nature et leur structure.

|                              | Python  | Pandas          |
| ---------------------------- | ------- | --------------- |
| Chaines de caract√®res, texte | `str`   | `object`        |
| Valeurs enti√®res num√©riques  | `int`   | `int32`/`int64` |
| Valeurs r√©elles √† virgule    | `float` | `float64`       |
| bool√©ens True ou False       | `bool`  | `bool`          |
| ...                          |         |                 |

```python
# V√©rifier les types du dataframe
print(df.dtypes)
```
---
## Importer/export

Pour Forcer PAndas √† afficher toutes les colonnes
```python
pd.set_option('display.max_columns', None)
```


### Lecture de fichier texte ou excel 

| options        | sp√©cifie le s√©parateur                         |
| -------------- | ---------------------------------------------- |
| `sep = ,`      | <font color='orange'>par d√©faut</font> virgule |
| `sep = \t`     | tabulation  (tab-separated values, SAP, Excel) |
| `sep = r‚Äô\s+‚Äô` | plusieurs espaces                              |
| `sep = ;`      | point virgule                                  |

| options        |                                                                 |
| -------------- | --------------------------------------------------------------- |
| `columns =`    | une liste des colonnes qu'on souhaite exporter                  |
| `Index = `     | `True`par d√©faut : √©crit les labels/index des lignes            |
| `sheet_name =` | si on veut un autre onglet que le 1er du fichier excel          |

#### option `header`

<font color='orange'>Par d√©faut, python prend la 1√®re ligne du fichier comme header</font>

Si le fichier source ne contient pas de header
On peut le sp√©cifier afin que python ne le cr√©e pas :
```python
nom_dataframe = pd.read_csv('nom_du_fichier.csv', header = None)
```
Les noms de colonne seront 0,1,2,3,etc...
Si le fichier source √† un header, il sera consid√©r√© comme la 1√®re ligne du tableau, cela peut g√©n√©rer des erreurs de type (`int` au lieu de `str` par exemple).



#### option `names`
Pandas ne prend pas le header du fichier et en cr√©e un avec les noms de colonnes en argument :
```python
nom_dataframe = pd.read_csv('nom_du_fichier.csv', names = ['colonne_1', 'colonne_2'] )
```

#### option `skiprows`
Permet d'ignorer certaines lignes lors de la lecture du fichier et ne les stocke pas dans le tableau :
```python
nom_dataframe = pd.read_csv('nom_du_fichier.csv', skiprows=1, header = None)
```


#### option `index_col`
Sp√©cifie quelle colonne du dataset correspond √† l'index
il est possible d'avoir plusieurs index :
```python
nom_dataframe = pd.read_csv('nom_du_fichier.csv', index_col = 0 )
# ou
nom_dataframe = pd.read_csv('nom_du_fichier.csv', index_col = [0,5] )
```

#### option `squeeze`
Cr√©e un `Serie` au lieu d'un `DataFrame` (par d√©faut)
```python
pd.read_csv("fichier.csv", squeeze=True)
```

#### option `usecols`
Si toutes les colonnes ne nous int√©ressent pas, on peut les filtrer 
```python
# filtrer avec les positions des colonnes
pd.read_csv("fichier.csv", usecols=[3,6])
# filtrer avec les noms des colonnes
pd.read_csv("fichier.csv", usecols=[colonne_nom, colonne_age])
```

#### option `dtype`
Sp√©cifier le type des colonnes avec un dictionnaire

| cl√©               | valeurs               |
| ----------------- | --------------------- |
| noms des colonnes | `dtype` de la colonne |

```python
pd.read_csv("fichier.csv", dtype{"colonne_1":"Int64", "colonne_2":"float64", "colonne_3":"object"})
```
---

#### üìÖ Gestion des dates : bonnes pratiques
Parser = analyser la syntaxe d'un texte

l'argument `parse_dates` indique quelles colonnes du fichier CSV doivent √™tre interpr√©t√©es comme des dates.
Converti automatiquement des colonnes contenant des dates en objets **datetime**
##### 1. Charger un fichier CSV avec une colonne de dates comme index

```python
# La colonne 'Date' devient l'index du DataFrame
# Pandas convertit automatiquement cette colonne en datetime
df = pd.read_csv(    "fichier.csv",index_col="Date", parse_dates=True)
```

* `index_col="Date"` est id√©al pour des s√©ries temporelles.
* `parse_dates=True` dit √† Pandas de d√©tecter les dates dans l'index.
* Le type obtenu est : `datetime64[ns]`.


##### 2. Convertir une colonne sp√©cifique en datetime lors du chargement

```python
# Convertit la 5√®me colonne (index 4) en datetime64[ns]
df = pd.read_csv("fichier.csv", parse_dates=[4])
```

* `parse_dates=[4]` permet de convertir uniquement certaines colonnes.
* Utile si le fichier a plusieurs colonnes date et que tu veux garder le contr√¥le.
* √âvite les mauvaises interpr√©tations si certaines colonnes ressemblent √† des dates sans en √™tre !


##### 3. Convertir une colonne en datetime apr√®s chargement
 `format` permet de forcer un format de date (FR / international)
```python
df["Date"] = pd.to_datetime(df["Date"], format="%d/%m/%Y")
```

###### Bonnes pratiques :

* Toujours utiliser `pd.to_datetime()` plut√¥t que `astype("datetime")`.
* G√®re beaucoup plus de formats automatiquement, et d√©tecte les erreurs.
* Si le fichier est fran√ßais (`31/12/2023`), Pandas peut se tromper.
* `format` rend la conversion **plus rapide** et **plus fiable**.


##### 4. G√©rer les erreurs de parsing proprement

```python
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
```

###### Effet :

* Les dates invalides deviennent `NaT` (√©quivalent de NaN pour les dates).
* Tr√®s utile pour nettoyer des fichiers Excel ou CSV mal form√©s.


##### 5. Extraire des informations temporelles utiles

```python
df["Ann√©e"] = df["Date"].dt.year
df["Mois"] = df["Date"].dt.month
df["Jour"] = df["Date"].dt.day
df["Semaine"] = df["Date"].dt.isocalendar().week
df["Jour_sem"] = df["Date"].dt.day_name()   # Monday, Tuesday‚Ä¶
```


##### 6. Trier par date (toujours n√©cessaire)

```python
df = df.sort_values("Date")
```

Indispensable avant :

* des graphiques temporels
* du resampling
* des calculs glissants (rolling)


##### 7. R√©sampling (tr√®s utile en time-series)

```python
df.resample("M").mean()   # donn√©es mensuelles
df.resample("W").sum()    # donn√©es hebdomadaires
df.resample("D").ffill()  # remplissage avant
```

##### 8. Identifier les fr√©quences temporelles

```python
pd.infer_freq(df.index)
```

Retourne `"D"`, `"M"`, `"H"`, etc.
‚úî Tr√®s utile pour v√©rifier que l‚Äôindex est uniforme.


üîπ la gestion desFuseaux horaires (`tz_localize`, `tz_convert`)
üîπ les dates irr√©guli√®res
üîπ les time deltas (`Timedelta`)

---

#### option `sheet_name`
Pour importer une autre feuille que la 1√®re du fichier excel
```python
# avec les positions des colonnes
pd.read_csv("fichier.csv", sheet_name="nom_de_la_feuille")
```

###  Importation depuis une base de donn√©e
exemple avec une bdd SQLite avec la fonction `read_sql`:

```python
import sqlite3
connexion = sqlite3.connect('../chemin/bdd.db')
requete = "SELECT * FROM nom_table;"
resultats = pd.read_sql(requete, con=connexion)
resultats.head()
```

### Lecture de fichier au format `.json`
format texte pour l'√©change de donn√©es de mani√®re structur√©e et l√©g√®re

```python
pd.read_json("../datasets/employees.json")
```



### Ecriture de fichier ou exportation de donn√©es
```python
mon_dataframe.to_csv("mes_resultats.csv")
```

| options      |                                                            |
| ------------ | ---------------------------------------------------------- |
| `sep`        | pour sp√©cifier le s√©parateur, par d√©faut c'est la virgule. |
| `columns`    | une liste des colonnes qu'on souhaite exporter             |
| `header`     | √©crire un en t√™te (par d√©faut)                             |
| `Index`      | `True`par d√©faut : √©crit les labels/index des lignes       |
| `sheet_name` | D√©fini le nom de la feuille (onglet)                       |

```python
mon_dataframe.to_csv("mes_resultats.csv", sep=";")
mon_dataframe.to_csv("mes_resultats.csv", columns=["colonne_1", "colonne_5"])
```

---
---
## Valeur manquante : `NaN` vs. `NA`


- **NaN** (`Not a Number`) de **NumPy** : valeur flottante limit√© aux **donn√©es num√©riques**.
- **NA** (`Not Available`) de **Pandas**: pour les **types non num√©riques** (textes, cat√©gories, etc.).


Pandas recommande d‚Äôutiliser **`pd.NA`** pour une meilleure gestion des donn√©es manquantes :<br>
**`pd.NA`** est plus flexible et fonctionne avec les types Pandas (`Int64`, `String`, `Boolean`).
  

| Caract√©ristique                       | `NaN` (`numpy.nan`)                        | `NA` (`pd.NA`)                                                     |
| ------------------------------------- | ------------------------------------------ | ------------------------------------------------------------------ |
| **Type**                              | `float`                                    | `pandas._libs.missing.NAType` (nullable)                           |
| **Utilisation principale**            | Donn√©es num√©riques                         | Donn√©es avec types *nullable* : `Int64`, `boolean`, `string`, etc. |
| **Comportement logique**              | `np.nan != np.nan`                         | `pd.NA == pd.NA` ‚Üí renvoie **`pd.NA`** (ind√©termin√©)               |
| **Comparaison (`==`)**                | Toujours `False` (m√™me `np.nan == np.nan`) | Renvoie `pd.NA`, pas `True`                                        |
| **Op√©rations math√©matiques**          | OK ‚Üí r√©sultat : `nan`                      | Souvent **erreur** (`TypeError`)                                   |
| **Support des dtypes nullable**       | ‚ùå Non                                      | ‚úÖOui                         |
| **D√©tect√© par `isna()` / `isnull()`** | ‚úÖOui                                     | ‚úÖ Oui                          |
| **Fonctionne avec `fillna()`**        | ‚úÖ                                        | ‚úÖ Oui                          |
| **Effet sur les dtypes**              | Force les colonnes en `float`              | Garde le type nullable d‚Äôorigine (`Int64`, `boolean`, `string`)    |
| **Compatibilit√© bool√©ens**            | Probl√©matique                              | Compatible avec `BooleanDtype()`                                   |
| **Types de donn√©es typiques**         | Floats                                     | Nullable Pandas types                                              |


<br>
‚û°Ô∏è Pour la data science classique : np.nan suffit<br>
‚û°Ô∏è Pour garder des colonnes int ou bool avec NA : utiliser pd.NA

Contrairement √† **Numpy**, **`pandas.DataFrame.sum()` ignore les `NaN`par d√©faut** :<br>
calcule la somme en ignorant les `NaN`comme `np.nansum()`

### Machine learning `NaN`‚úÖ, `Na`‚ùå 
Les biblioth√®ques ML attendent presque toutes des `NaN` :
- scikit-learn
- XGBoost
- LightGBM
- CatBoost
- TensorFlow / Keras
- PyTorch
-statsmodels

Toutes s‚Äôattendent explicitement √† recevoir des `floats` et des `np.nan` pour repr√©senter les valeurs manquantes<br>
`pd.NA` n‚Äôest pas reconnu dans la majorit√© des mod√®les.



#### `NaN` (`numpy.nan`)

- `Not a Number`
	utilis√© principalement pour repr√©senter des valeurs num√©riques manquantes.
- **Type** : `float`
- **Provenance** : `numpy.nan`


| NaN                           | Not a Number                                         |
| ----------------------------- | ---------------------------------------------------- |
| `NaN != NaN`                  | Deux `NaN` ne sont **jamais √©gaux** entre eux        |
| `type(np.nan)`                | `float`                                              |
| `pd.isna(x)`<br>`np.isnan(x)` | Teste si une valeur est un `NaN`                     |
| `np.nansum()`                 | somme de tous les √©l√©ments en **ignorant** les `NaN` |



```python
df = pd.DataFrame({"A": [1, 2, np.nan, 4]})

         A
    0  1.0
    1  2.0
    2  NaN
    3  4.0
```

#### NA (`pd.NA`)

- `Not Available` : Valeur manquante g√©n√©rique, introduite dans Pandas 1.0 pour g√©rer √† la fois les types num√©riques et non num√©riques.<br>
**donn√©es non num√©riques** ou **cat√©gorielles** ou **`object`**, `str`
- **Type** : `pd.NA` (au lieu de `float`)
- **Provenance** : Pandas (`pd.NA`)
- **Meilleure compatibilit√©** avec les `Int64`, `String`, et `Boolean`
- fait partie du type `pd.NA`, pour g√©rer de mani√®re uniforme les valeurs manquantes.
  
   
```python
df = pd.DataFrame({"A": [1, 2, pd.NA, 4]})

         A
    0    1
    1    2
    2  <NA>
    3    4
```

	
### Gestion des `NaN` et `NA`

Pandas a √©t√© con√ßu pour que ces fonctions traitent tous les types de valeurs manquantes :
- `np.nan` (float NaN)
- `None`
- `pd.NA` (nouveau syst√®me NA de pandas)
- `pd.NaT` (date manquante)

‚Üí Toutes sont d√©tect√©es par `isna()` / `isnull()` et g√©r√©es par `fillna()` et `dropna()`

V√©rifier la pr√©sence de valeurs manquantes

```python
df.isna()  # Identique √† df.isnull()
df.isna().any()      # False ou True, colonne par colonne
df.isna().any().any() # True si au moins un NaN quelque part
```

Remplacer les valeurs manquantes

```python
df.fillna(0)  # Remplace NaN ou NA par 0
```

`fillna` remplace tous les NaN par :

```python
# 0
df.fillna(0)
# la derni√®re valeur connue (forward fill)
df.fillna(method='ffill')
# la prochaine valeur connue (backward fill)
df.fillna(method='bfill')
# la moyenne de chaque colonne
df.fillna(df.mean())
```

DataFrame de 3 colonnes, 4 lignes, avec des valeurs manquantes :
```python
df = pd.DataFrame({
    'A': [1, 2, np.nan, 4],
    'B': [np.nan, 2, 3, np.nan],
    'C': [1, np.nan, np.nan, 4]
})
```

	Original        ->        ffill            ->        bfill

| A   | B   | C   |     | A   | B   | C   |     | A   | B   | C   |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
|     |     |     |     |     |     |     |     |     |     |     |
| 1   | NaN | 1   | ->  | 1   | Nan | 1   | ->  | 1   | 2   | 1   |
| 2   | 2   | NaN |     | 2   | 2   | 1   |     | 2   | 2   | 4   |
| NaN | 3   | NaN |     | 2   | 3   | 1   |     | 4   | 3   | 4   |
| 4   | NaN | 4   |     | 4   | 3   |     |     | 4   | NaN | 4   |

Supprimer les lignes contenant des valeurs manquantes

```python
df.dropna()

# supprime les lignes o√π la colonne `"ma_colonne"` contient des NaN
df.dropna(subset=["ma_colonne"])

```
---










---

## Methodes

| M√©thode           | `Series` | `DataFrame` |
| ----------------- | -------- | ----------- |
| `.sort_values()`  | ‚úÖ        | ‚úÖ           |
| `.loc`            | ‚úÖ        | ‚úÖ           |
| `.iloc`           | ‚úÖ        | ‚úÖ           |
| `.groupby()`      | ‚ùå        | ‚úÖ           |
| `.drop()`         | ‚ùå        | ‚úÖ           |
| `del`             | ‚ùå        | ‚úÖ           |
| `.pop()`          | ‚ùå        | ‚úÖ           |
| `.rename()`       | ‚ùå        | ‚úÖ           |
| `.astype()`       | ‚úÖ        | ‚úÖ           |
| `pd.to_numeric()` | ‚úÖ        | ‚úÖ           |
| `.nunique()`      | ‚úÖ        | ‚úÖ           |
| `.reset_index()`  | ‚ùå        | ‚úÖ           |
| `.pivot_table()`  | ‚ùå        | ‚úÖ           |
| `pd.concat()`     | ‚ùå        | ‚úÖ           |
| `.merge()`        | ‚ùå        | ‚úÖ           |
| `.join()`         | ‚ùå        | ‚úÖ           |
|                   |          |             |


### M√©thodes des objets de classes `Series`
[Doc](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)

| m√©thodes pour les s√©ries |                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `describe()`             | affiche un r√©sum√© statistique sur les valeurs de la s√©rie :<br>`count`  nombre sans compter les valeurs manquante<br>`mean`    moyenne <br>`std`      d√©viation standard √©cart type<br>`min`      valeur minimum<br>`25%`      quartiles ,divise le donn√©es en 4 parts √©gales<br>`50%`      des individus font moins que la valeur<br>`75%`      des individus font moins que la valeur<br>`max`      valeur maximum |
| `value_count()`          | visualise les valeurs uniques et leurs nombre                                                                                                                                                                                                                                                                                                                                                                        |
| `replace()`              | remplace une ou +ieurs valeurs par une autre                                                                                                                                                                                                                                                                                                                                                                         |
| `set_index()`            | red√©fini les index                                                                                                                                                                                                                                                                                                                                                                                                   |

### Ajouter  des valeurs

La m√©thode `pd.concat()` permet de concat√©ner des `Series` ou des `DataFrame`.  
On peut concat√©ner plusieurs objets de m√™me type (`Series` avec `Series`, ou `DataFrame` avec `DataFrame`).  
Cela permet d'ajouter des lignes ou des colonnes selon l'axe sp√©cifi√©.

Par s√©curit√©, `pd.concat()` retourne une copie (un nouvel objet) et n'applique pas le traitement sur l'objet original.

On peut lui assigner le m√™me nom pour forcer le changement de l'original :

#### Pour une `Series` :

```python
ma_serie = pd.concat([ma_serie, pd.Series([liste_valeurs], index=["liste de label"])])
```

#### Pour un `DataFrame` :

```python
mon_dataframe = pd.concat([mon_dataframe, pd.DataFrame([[liste_valeurs]], columns=["colonne1", "colonne2"])], ignore_index=True)
```

- Pour concat√©ner des `Series` ou des `DataFrame`, `pd.concat()` peut √™tre utilis√© pour ajouter des lignes (par d√©faut) ou des colonnes, selon l'argument `axis`.
- Par d√©faut, `axis=0` ajoute des lignes, et `axis=1` ajoute des colonnes.

Cela couvre les deux cas d'usage !


### Supprimer une valeur

La m√©thode `drop()` permet de supprimer des √©l√©ments (lignes ou colonnes) en fonction de leur √©tiquette d'index sp√©cifi√©e en option.

#### Pour une `Series` :

```python
ma_serie.drop(labels=["index_1", "index_2"], inplace=False)
```

#### Pour un `DataFrame` :

```python
mon_dataframe.drop(labels=["index_1", "index_2"], axis=0, inplace=False)  # Supprimer des lignes
# ou
mon_dataframe.drop(labels=["colonne1", "colonne2"], axis=1, inplace=False)  # Supprimer des colonnes
```

| `inplace=False`  | La modification est effectu√©e sur une copie        | Par d√©faut |
| ---------------- | -------------------------------------------------- | ---------- |
| `inplace=True`   | La modification est effectu√©e sur l'objet original |            |

#### Remarque :

- La m√©thode `drop()` modifie l'objet en place uniquement si `inplace=True` est sp√©cifi√©.
- Sur une `Series`, cela supprimera des √©l√©ments selon leur √©tiquette d'index.
- Sur un `DataFrame`, cela supprime des lignes (`axis=0`, par d√©faut) ou des colonnes (`axis=1`).

### Modifier les valeurs

Les indexeurs `loc` et `iloc` sont utilis√©s pour modifier des valeurs dans une `Series` ou un `DataFrame`.

#### Avec `loc` (pour une `Series` ou un `DataFrame`), on s√©lectionne par √©tiquette d'index :

```python
ma_serie.loc["nom_index"] = nouvelle_valeur
# ou pour modifier plusieurs valeurs :
ma_serie.loc["nom_index_1", "nom_index_2"] = [nouvelle_valeur_1, nouvelle_valeur_2]
```

#### Avec `iloc` (pour une `Series` ou un `DataFrame`), on s√©lectionne par position d'index :

```python
ma_serie.iloc[position] = nouvelle_valeur
```

- **`loc`** : Lorsque plusieurs √©l√©ments ont la m√™me √©tiquette d'index dans une `Series` ou un `DataFrame`, toutes les occurrences seront modifi√©es.
- **`iloc`** : Chaque position est unique, donc **seule l'occurrence √† la position donn√©e sera modifi√©e**.

#### Exemple avec une `Series` :

```python
# Modifier la valeur √† l'index 'nom_index'
ma_serie.loc["nom_index"] = "nouvelle_valeur"

# Modifier la valeur dans une `Series` avec un autre index
ma_serie.iloc[2] = "nouvelle_valeur_position_2"
```

#### Exemple avec un `DataFrame` :

```python
# Modifier une cellule en utilisant `loc`
mon_dataframe.loc[3, "nom_colonne"] = "nouvelle_valeur"

# Modifier plusieurs cellules
mon_dataframe.loc[2, ["colonne1", "colonne2"]] = ["valeur1", "valeur2"]
```

Les indexeurs permettent de manipuler les donn√©es de mani√®re flexible selon les besoins de s√©lection et de modification.


---
## `Serie`
objet, structure de donn√©e

colonne du data frame,
tableau √† 1 dimension (vecteur),
suite de valeurs repr√©sentant une variable pour un ensemble d'observation/individu

poss√®de :
- un nom
- des <font color='orange'>index</font> `index`par d√©faut des `√¨nt` √† partir de 0, incr√©mente de 1
  peut √™tre remplacer par des <font color='orange'>√©tiquettes</font> du type que l'on souhaite
- des valeurs `values()`
- un seul axe, l'axe des index

Acc√®s aux valeurs de la s√©rie :
- avec la \[ position de la valeur \]
- avec l'\[ √©tiquette \]


[ensemble des m√©thodes et attributs des Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)

### Cr√©er une `Serie`

Le stockage de valeurs de types h√©t√©rog√®nes est permis mais il est fortement conseill√© de n'utilis√© qu'<font color='orange'>un seul type de donn√©e</font>.

- m√©thode `Series()`
  √† partir d'une liste, d'un tableauNumPy, d'un distionnaire
- fonctions de lecture de fichier `read_table()`, `read_csv()
    ```python
  ma_serie=pd.Series(donnees)
  
  ma_serie_2=pd.read_table('chemin_du_fichier.txt')
```

#### √† partir de valeurs al√©atoires
Avec `choice` du module `random` de NumPy :
```python
# syntaxe
pd.Series(np.random.choice(data, size))
# exemple pour 10 valeurs entre 0 et 500 (exclu)
pd.Series(np.random.choice(list(range(0,500)), 10))
```
`dtype: int32` ou `int64`
#### √† partir d'une liste
Attention car <font color='orange'>les listes acceptent des donn√©es h√©t√©rog√®ne, ce n'est pas conseill√©</font>
La serie aura alors le `dtype: object` qui correspond au `str` et aux types mixtes
```python
# syntaxe
ma_serie=pd.Series(numpy_array)
```

#### √† partir d'un tableau Numpy (ndarray)
```python
# syntaxe
pd.Series(liste)
# exemple avec 10 valeurs entre 0 et 499
ma_serie=pd.Series([2,5,7,'T',False])
```

#### √† partir d'un fichier texte
```python
# avec la colonne 5 seulement
ma_serie=pd.read_csv('mon_fichier.csv', usecols=[5], squeeze=True)
```
#### Choisir l'index d'une s√©rie
```python
# avec les colonnes 5 et 7, la colonne 5 sert d'index
ma_serie=pd.read_csv('mon_fichier.csv', usecols=[5,7], index_col=[5], squeeze=True)
```


Affiche le type d'une colonne (variable) avec la fonction `type`:
```python
type(nom_dataframe[nom_variable])
```

### Acc√©der aux valeurs d'une `Serie`

Indexing : vouloir  acc√©der √† un sous ensemble de notre structure
#### Indexing via la position des valeurs

```python
# Acc√©der √† la position 2
ma_serie[1]
# Acc√©der aux positions 2, 8 et 13
ma_serie[[1,7,12]]
# Acc√©der √† la derni√®re valeur
ma_serie[-1]
```

#### Indexing via l'√©tiquette des valeurs

```python
# Acc√©der √† la valeur dont l'√©tiquette est le string 'patates'
ma_serie["patates"]
# Acc√©der a plusieurs valeurs 
ma_serie[["patates","carottes","concombres"]]
# Acc√©der √† la derni√®re valeur
ma_serie[-1]
```


#### Indexeurs loc et iloc

Si les √©tiquettes sont des entier (comme les positions), Pandas ne saura pas ce que l'on cherche.

```python
# effectue l'indexing sur les √©tiquettes
ma_serie.loc[etiquette]
# effectue l'indexing sur les position 
ma_serie.iloc[position]

```


#### Indexing via une expression bool√©enne

Se base sur les valeurs et pas sur les positions.

```python
ma_serie[ma_serie>10]

ma_serie[ (ma_serie>10) & (ma_serie<30) ]
```
1. cr√©e une nouvelle s√©rie de la m√™me taille , contenant des valeurs bool√©ennes
2. r√©cup√®re l'ensemble des valeurs `True`

Effectuer plusieurs op√©rations bool√©ennes avec les op√©rateurs bitwise :

| [[Op√©rateurs bitwise]] |          | touche Mac  |
| ---------------------- | -------- | ----------- |
| `&`                    | et       |             |
| \|                     | ou       |             |
| ~                      | n√©gation | `alt` + `N` |

Les op√©rateurs logiques fonctionnent bien sur des expressions qui renvoient une valeur unique, avec les `Serie`ils renvoient une erreur



#### Slicing : d√©coupage de valeurs successive

[Voir le slicing avec Python](Python.md#SLICING)  stop non inclus

R√©cup√®re un sous ensemble de donn√©es
S√©lectionne les valeurs et les index.
N'utilise que les positions, pas les √©tiquettes (g√©n√®re une erreur)

```python
# Avec les crochets
ma_serie[start:stop:step]
# Avec iloc - Conseill√©
ma_serie.iloc[start:stop:step]

# Toutes les valeurs de la s√©rie sauf les 2 derni√®res
ma_serie.iloc[:-2]
# Seulement les 2 derni√®res valeurs
ma_serie.iloc[-2:]
```
### M√©thodes des objets de classes `Series`
[Doc](https://pandas.pydata.org/docs/reference/api/pandas.Series.html)

| m√©thodes pour les s√©ries |                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `describe()`             | affiche un r√©sum√© statistique sur les valeurs de la s√©rie :<br>`count`  nombre sans compter les valeurs manquante<br>`mean`    moyenne <br>`std`      d√©viation standard √©cart type<br>`min`      valeur minimum<br>`25%`      quartiles ,divise le donn√©es en 4 parts √©gales<br>`50%`      des individus font moins que la valeur<br>`75%`      des individus font moins que la valeur<br>`max`      valeur maximum |
| `value_count()`          | visualise les valeurs uniques et leurs nombre                                                                                                                                                                                                                                                                                                                                                                        |
| `replace()`              | remplace une ou +ieurs valeurs par une autre                                                                                                                                                                                                                                                                                                                                                                         |
| `set_index()`            | red√©fini les index                                                                                                                                                                                                                                                                                                                                                                                                   |





### Ajouter, supprimer modifier des valeurs d'une `Serie`

La m√©thode `append()`permet de concat√©ner des `Series`
On donne un objet de type `Serie`√† la m√©thode `append()`
une liste de valeurs et une liste optionnelle d'index correspondant 

Par s√©curit√©, `append()`retourne une copie (un nouvel objet) et n'applique pas le traitement sur l'objet original

On peut lui assigner le m√™me nom pour forcer le changement de l'original

```python
ma_serie =
ma_serie.append(pd.Series([liste_valeurs], index=["liste de label"]))
```

### Supprimer une valeur d'une `Serie`

m√©thode `drop()`
supprime les valeurs aux √©tiquettes d'index sp√©cifi√© en option.

```python
ma_serie.drop(labels=["index_1", "index_2"], inplace=False)
```

| option `inplace` | n'existe pas dans la m√©thode `append()`            |            |
| ---------------- | -------------------------------------------------- | ---------- |
| `inplace=False`  | la modification est effectu√©e sur une copie        | par d√©faut |
| `inplace=True`   | la modification est effectu√©e sur l'objet original |            |








### Modifier les valeurs d'une `Serie`
indexeurs `loc`et `iloc`
```python
ma_serie.loc["nom_index"] = nouvelle_valeur
# ou
ma_serie.loc["nom_index_1", "nom_index_2"] = [nouvelle_valeur_1, nouvelle_valeur_2]
# ou
ma_serie.iloc[position] = nouvelle_valeur
```

Avec `loc`, si un nom d'index a plusieurs occurences, elle seront toutes modifi√©es
Avec `iloc`une seule occurence serait modifi√©e ( les positions sont unique )




---
---
## `Dataframe`

objet, structure de donn√©e, tableau √† 2 dimensions

- Les index des lignes : axe 0 ‚Üì
et
- les noms de colonnes : axe 1 ‚Üí

permettent d'acc√®der aux donn√©es
Reprend les m√™mes paradigmes que les ndarray de [[Numpy]]

| `axis`   | Direction    | Cela veut dire                                                           |
| -------- | ------------ | ------------------------------------------------------------------------ |
| `axis=0` | vertical  ‚Üì  | **On op√®re sur les lignes**, on applique l'op√©ration colonne par colonne |
| `axis=1` | horizontal ‚Üí | **On op√®re sur les colonnes**, on applique l'op√©ration ligne par ligne   |


| Pandas    | Slice python | veut dire                              |
| --------- | ------------ | -------------------------------------- |
| `df.iloc` | `[:,-1]`     | toutes les lignes, la derni√®re colonne |
| `df.iloc` | `[:-1]`      | toutes les lignes sauf la derni√®re     |
| `df.iloc` | `[:, :-1]`   | toutes les colonnes sauf la derni√®re   |



| index | A   | B   | C   |
| ----- | --- | --- | --- |
| 0     | 5   | 5   | 5   |
| 1     | 5   | 5   | 5   |
| 2     | 2   | 5   | 8   |
```python
# somme des colonnes (ligne par ligne pour chaque colonne)
df.sum(axis=0)
```
A = 12
B = 15
C= 18
```python
df.sum(axis=1)
```
0 = 15
1 = 15
2 = 15







```python
# Lire un fichier .txt
pd.read_table('chemin_du_fichier.txt')
# Lire un fichier csv
pd.read_csv('chemin_du_fichier.csv')

'''La seule diff√©rence entre ces 2 fonctions est la valeur de l'option s√©parateur :
sep = "/t"      (tabulation en python)
sep = ","
sep = ";"
sep = " "
'''

# enregistrer le dataframe dans une variable
nom_dataframe = pd.read_csv('nom_du_fichier.csv')
# affiche les 5 premi√®re lignes pour v√©rifier l'import
nom_dataframe.head()

# Lire un fichier json
pd.read_json('nom_du_fichier.json')

# Lire un fichier excel
pd.read_excel('nom_du_fichier.xlsx')
```

Par d√©faut, les fonctions de lecture de fichier de Pandas cr√©ent un `DataFrame`, m√™me √† partir d'un fichier avec une seule colonne.

Les donn√©es sont repr√©sent√©es et manipul√©es sous un format de tableau en python:
- chaque <font color="orange">ligne</font> repr√©sente un <font color="orange">individu</font> ou <font color="orange">observation</font>
- chaque <font color="orange">colonne</font> une <font color="orange">variable</font>.
- <font color="orange">chaque colonne peut √™tre d‚Äôun type diff√©rent, mais une colonne ne peut contenir qu‚Äôun seul type¬†!</font>

L‚Äôobjet `DataFrame` de Pandas permet de manipuler simplement et efficacement les donn√©es¬†et acc√©de facilement aux caract√©ristiques g√©n√©rales des jeux de donn√©es :

- comme les types de variables
- le nombre de lignes
- le nombre de colonnes
- etc ...

### caract√©ristique globale du data frame

```python
nom_dataframe.shape
```

retourne un tuple :  ( nombre de lignes,  nombre de colonnes)

```python
dim = nom_dataframe.shape
print(dim[0]) # 228 lignes
print(dim[1]) #   4 colonnes
```

- la m√©thode ¬†`.head()`¬† s√©lectionne par d√©faut les 5¬†premi√®res lignes du data frame.     
- la m√©thode ¬†`.tail()`¬† s√©lectionne par d√©faut les 5¬†derni√®res lignes du data frame. 
- Il est possible de pr√©ciser entre parenth√®ses le nombre de lignes √† afficher

Types de chacune de nos variables. On peut acc√©der √† cela tr√®s simplement √† partir de l‚Äôattribut ¬†`.dtypes`¬† :

```python
nom_dataframe.dtypes
```

Transformer un data frame en array¬†:

```python
clients_array = nom_dataframe.values
display(clients_array)
```

### Naviguer dans un data frame

Acc√©der √† une colonne (variable) d‚Äôun data frame, il suffit d‚Äôutiliser la syntaxe
```python
nom_dataframe[nom_variable]
```

Stocker dans une variable la variable 'email' du dataframe :
```python
email = nom_dataframe['email']
```

Acc√©der √† plusieurs colonnes (variables)

- stocker les noms des colonnes dans une liste :
```python
variables = ['nom', 'email']
nom_dataframe[variables]

# version courte :
nom_dataframe[['nom', 'email']]
```
Les variables s‚Äôaffichent dans l‚Äôordre sp√©cifi√©, sans modifier le data frame initial.


### indexing d'un `DataFrame`

Comme avec les `Serie`mais il faut donner 2 ensembles de valeurs, 1 pour les lignes, 1 pour les colonnes.

#### indexing et slicing avec l'attribut `loc`
s√©lectionne les donn√©es selon les √©tiquettes des lignes et le noms de colonnes
```python
# s√©lectionne une valeur unique
dataframe.loc["nom_ligne", "nom de colonne"]
# s√©lectionne 2 valeurs sur 2 lignes et une seule colonne
dataframe.loc[["nom_ligne", "nom_ligne_2"], ["nom_de_colonne", "nom_de_colonne"]]
# s√©lectionne une ligne et toutes les colonnes
dataframe.loc["nom_ligne", :]
# s√©lectionne toutes les lignes et une colonne
dataframe.loc[:, ["nom_de_colonne"]]

```




 ### Modifier une colonne (variable)

Pour modifier ou cr√©er une colonne`col`¬†, la syntaxe sera¬†: 
```python
mon_dataframe['col'] = x
```
o√π `x` repr√©sente soit une valeur fixe, soit un objet de m√™me dimension que la colonne qu‚Äôon souhaite modifier/cr√©er.

### Supprimer une colonne (variable)

Il existe officiellement 3 fa√ßons :

1. La m√©thode`.drop`
```python
nom_dataframe.drop(columns='id')
```
<font color='orange'>La m√©thode `.drop`¬†ne modifie pas le data frame existant.</font>
Elle renvoie une de copie du data frame en y ayant appliqu√© les modifications¬†‚Äì ici supprimer la colonne id.

Vous aurez besoin de remplacer votre data frame pour pallier cela¬†:
```python
nom_dataframe = nom_dataframe.drop(columns='id')
```

2. Le mot cl√© `del`¬†
```python
del nom_dataframe['id']
```

3. la m√©thode`.pop`¬†
```python
nom_dataframe.pop('id')
```

### Renommer une ou plusieurs colonnes
```python
mon_dataframe.rename(columns={'ancien nom': 'nouveau nom'})
data.rename(columns={'identifiant': 'ide','email': 'mail'})
```

<font color='orange'>La m√©thode `rename` ne modifie pas le data frame existant</font>.
Il existe un argument pour cette m√©thode (et pour toutes les m√©thodes similaires) nomm√© ¬†`inplace`¬†, qu‚Äôil suffit de fixer √† `True` :

```python
data.rename(columns={'identifiant': 'ide'}, inplace=True)¬† 

# est strictement √©quivalent √† ¬†

data = data.rename(columns={'identifiant': 'ide'})
```

### Changez le type d‚Äôune colonne

#### La m√©thode`.astype`¬†permet de changer le type d‚Äôune colonne¬†:
Il faut pr√©ciser le type entre parenth√®ses
```python
data['identifiant'].astype(float)
```


#### La m√©thode`.to_numeric`
```python
pd.to_numeric(arg, errors='raise', downcast=None)
```
Param√®tres :
1. **`arg`** :
    - Les donn√©es √† convertir (peut √™tre une liste, une s√©rie, ou un DataFrame).
    - Exemple : Une colonne contenant des cha√Ænes comme `'123'`, `'45.67'`.
2. **`errors`** :
    - Contr√¥le comment les erreurs sont g√©r√©es lors de la conversion.
    - Options :
        - **`'raise'`** (par d√©faut) : L√®ve une erreur si une valeur ne peut pas √™tre convertie.
        - **`'coerce'`** : Remplace les valeurs non convertibles par `NaN`.
        - **`'ignore'`** : Laisse les donn√©es inchang√©es si elles ne peuvent pas √™tre converties.
3. **`downcast`** :
    - Essaie de r√©duire la pr√©cision des donn√©es pour √©conomiser de la m√©moire.
    - Options : `'integer'`, `'float'`, ou `'unsigned'`.

Retourne :

- Une **`Series`** ou un **`DataFrame`** (selon l'entr√©e), o√π les valeurs sont converties en types num√©riques (`int64`, `float64`, etc.).

### Valeurs unique ?

m√©thode `nunique()` pour compter le nombre de valeurs uniques dans la colonne. Si le r√©sultat est 1, toutes les valeurs sont identiques :

```python
# V√©rifier si toutes les valeurs sont identiques
if mon_dataframe['ma_colonne'].nunique() == 1:
	print("Toutes les valeurs de ma_colonne sont identiques.")
else:
	print("Toutes les valeurs de ma_colonne ne sont pas identiques.")
```

### Triez un data frame `.sortvalues`

La m√©thode`.sort_values`¬†
Pr√©ciser entre parenth√®ses la ou les colonnes selon lesquelles il faut trier¬†:

```python
# trier selon l‚Äôidentifiant, par ordre croissant :
data.sort_values('identifiant')

#trier selon l‚Äôidentifiant par ordre d√©croissant :
data.sort_values('identifiant', ascending = False)

# trier selon le genre puis le nom, par ordre croissant :
data.sort_values(['genre', 'nom'])

# par genre en ordre croissant et par nom en ordre d√©croissant
clients.sort_values(['genre', 'nom'], ascending=[True, False])
```

- On peut s√©lectionner une ou plusieurs colonnes d‚Äôun data frame via la syntaxe ¬†`mon_dataframe[col]`, o√π¬†`col`¬†est soit le nom de la colonne √† s√©lectionner (lorsqu‚Äôil n'y en a qu‚Äôune), soit une liste de noms de colonnes (lorsqu‚Äôil y en a plusieurs).

- Pandas trie par colonne par d√©faut

- Une colonne d‚Äôun data frame est une s√©rie Pandas.

- De nombreuses manipulations sont possibles avec/via des s√©ries ; on peut notamment¬†:

    - modifier, ajouter ou supprimer une colonne
    - modifier le nom d‚Äôune colonne via la m√©thode`.rename()`
    - changer le type d‚Äôune colonne via la m√©thode`.astype()`¬†
    - trier un data frame via la m√©thode`.sort_values()`


### ¬†Filtrer des donn√©es `.loc .i`loc`

### m√©thode`.iloc`
permet de s√©lectionner √† partir des indices
```python
mon_dataframe.iloc[indice_ligne, indice_colonne]
```

   s√©lectionner toutes les colonnes des 10 premi√®res ligne de l'array 'clients' :
```python
clients.iloc[:10, :]
```

   s√©lectionner les colonnes 2 et 4 des 10 derni√®res lignes :
```python
clients.iloc[-10:, [1, 3]]
```

### m√©thode `.loc`
permet de s√©lectionner.

```python
mon_dataframe.loc[ index _lignes, index_colonne ]

mon_dataframe.loc[ condition sur les lignes, colonne(s) ]
```

### <font color='red'>indices</font>
position intrins√®que d‚Äôun √©l√©ment au sein d‚Äôun tableau.
est <font color='red'>relatif aux op√©rations r√©alis√©es</font>.

### <font color='red'>index</font>
<font color='red'>une ligne</font> - quelle que soit sa position dans le data frame - <font color='red'>aura toujours le m√™me index</font>
peu importe les op√©rations effectu√©es.
C'est une valeur unique qui est associ√©e intrins√®quement √† chaque ligne, sur la gauche du data frame.
Par d√©faut, ils correspondent aux indices.
Peuvent ne pas √™tre num√©riques


Il est possible de r√©initialiser ce dernier via la m√©thode ¬†`.reset_index`¬†.
### m√©thode `.reset_index()`

- La condition sur les lignes est une condition qui va √™tre test√©e sur chaque ligne.
  Une ligne est conserv√©e dans le processus de s√©lection si elle satisfait √† cette condition.
  Cette condition peut √™tre une conjonction de plusieurs conditions s√©par√©es par des "et" logiques (`&`¬†) ou des "ou" logiques (`|`¬†)

- Les index sont des valeurs qui sont associ√©es intrins√®quement √† chaque ligne. Si on effectue un tri ou toute autre op√©ration, une ligne, quelle que soit sa position dans le data frame, aura toujours le m√™me index. Il est possible de r√©initialiser ce dernier via la m√©thode ¬†`.reset_index`¬†

- La m√©thode`.loc`¬†peut √™tre √©galement utilis√©e pour modifier la partie du data frame s√©lectionn√©e.
### R√©sum√©
- Il existe deux m√©thodes pour s√©lectionner pr√©cis√©ment des √©l√©ments au sein d‚Äôun data frame¬†:¬†

    - La m√©thode`.iloc`¬†permet de s√©lectionner √† partir des indices. La syntaxe est : ¬†`mon_dataframe.iloc[ indice(s) ligne ,¬† indice(s) colonne ]`¬† .

    - La m√©thode`.loc`¬†permet de s√©lectionner √† partir de conditions et des noms de colonnes. La syntaxe est : ¬†`mon_dataframe.loc[ condition sur les lignes ,¬† colonne(s) ]`¬† .

- La condition sur les lignes est une condition qui va √™tre test√©e sur chaque ligne. Une ligne est conserv√©e dans le processus de s√©lection si elle satisfait √† cette condition. Cette condition peut √™tre une conjonction de plusieurs conditions s√©par√©es par des :
	- `&`    "et" logiques
	- `|`¬†   "ou" logiques 


- Les index sont des valeurs qui sont associ√©es intrins√®quement √† chaque ligne. Si on effectue un tri ou toute autre op√©ration, une ligne, quelle que soit sa position dans le data frame, aura toujours le m√™me index. Il est possible de r√©initialiser ce dernier via la m√©thode ¬†`.reset_index`¬†.

- La m√©thode`.loc`¬†peut √™tre √©galement utilis√©e pour modifier la partie du data frame s√©lectionn√©e.





---
## Agr√©ger des donn√©es`.group_by` et `.pivot_table

¬†Une **agr√©gation** est une op√©ration tr√®s courante sur des data frames, soit pour analyser les donn√©es sous un certain angle, soit pour recalculer certaines variables
### Agr√©gez des lignes

La premi√®re m√©thode pour faire une agr√©gation avec Pandas est¬†**`.group_by`**¬†.¬†

1. Se¬†**fixer**¬†sur une ou plusieurs colonnes, qui seront ce qu‚Äôon appelle les¬†**index**¬†du r√©sultat agr√©g√©. L‚Äôindex permet de cr√©er plusieurs groupes¬†: un pour chaque valeur unique de l‚Äôindex.
2. Choisir une¬†**fonction d‚Äôagr√©gation**. La fonction d‚Äôagr√©gation va prendre en entr√©e un groupe de plusieurs lignes, pour effectuer un calcul sur celles-ci dans l‚Äôoptique de retourner¬†_une unique valeur pour chacun des groupes_

C'est similaire √† l‚Äôop√©ration de GROUP BY r√©alisable en [[SQL]]

##### **Exemple  1 :**
On souhaite calculer la moyenne de la variable`col`¬†pour chaque valeur de la variable`fix`¬†. 
![.group_by](img/pandas/group_by_1.bmp)

```python
dataframe.groupby('fix').mean()
```

Dans un premier temps, notre index sera la variable`fix`¬†
2¬†groupes sont cr√©√©s, un pour chaque valeur dans la variable`fix`¬†.
![.group_by](img/pandas/group_by_2.bmp)

Sur chacun de ces groupes, on applique la fonction d‚Äôagr√©gation choisie (moyenne).
#### **Exemple 2 : Agences bancaires qui font des pr√™ts dans plusieurs villes**

Le chiffre d'affaires total de chacune des agences

```python
prets.groupby('agences').sum()
```

Le chiffre d'affaires total par agence ET par type de pr√™t 
transmettre la liste des variables √† placer en index

```python
prets.groupby(['ville', 'type']).sum()
```

Avoir le r√©sultat seulement sur la variable¬†_remboursement_¬†:

```python
prets.groupby(['ville', 'type'])['remboursement'].sum()
```

Appliquer plusieurs fonctions d‚Äôagr√©gation sur une m√™me colonne.
Appliquer des fonctions d‚Äôagr√©gation diff√©rentes en fonction de la colonne.

Calcul la moyenne et la somme de`remboursement`¬†par agence, ainsi que le maximum de`revenu`¬† :

```python
prets.groupby('ville').agg({'remboursement': ['sum', 'mean'],
    'revenu': 'max'})
```

<font color='orange'>Avec `group_by`¬†, les variables fix√©es en index se retrouvent‚Ä¶ en index.</font> C‚Äôest-√†-dire que si vous essayez d‚Äôacc√©der √† la variable`ville`¬†du r√©sultat du¬†_group by_, vous aurez simplement une erreur¬†!
Il faut effectuer un`reset_index`¬†pour la replacer en ‚Äúcolonne‚Äù.

### Agr√©gez des lignes et des colonnes

m√©thode¬†**`.pivot_table`** prend 4¬†arguments en param√®tres¬†:

- **index**¬†: variable(s) plac√©e(s) en ligne ;
- **columns**¬†: variable(s) plac√©e en colonne(s) ;
- **values**¬†: variable sur laquelle on va appliquer la fonction d‚Äôagr√©gation ;
- **aggfunc**¬†: fonction d‚Äôagr√©gation.

La m√©thode permettant la transformation inverse s‚Äôappelle¬†**`melt`**¬†.





## Fusionner des donn√©es `.concat` et `.merge`

Il existe deux fa√ßons de _fusionner_ deux data frames¬†:¬†

- si les data frames ont la m√™me structure, on peut faire une concat√©nation via la fonction¬†`concat`¬†: mettre les 2¬†data frames bout √† bout 

- sinon, on peut faire une jointure via les fonction/m√©thode`merge`¬†.
### Concat√©ner des donn√©es
Syntaxe :
Placer l‚Äôensemble des dataframes dans une liste, et utiliser la fonction¬†`concat`¬†sur cette liste.
```python
liste_concat = [dataframe_1, dataframe_2]
pd.concat(liste_concat)
```
La **concat√©nation** assemble plusieurs data frames qui ont la m√™me structure
m√™mes colonnes,  m√™mes types.

 Ce n'est pas une [jointure](Pandas.md#jointure) (dimension horizontale)
 La concatenation mets l‚Äôun √† la suite de l'autre (dimension verticale)
 Comme lors d‚Äôun ajout d'√©l√©ment √† une liste, via la m√©thode ¬†`append`

<font color='orange'>La concat√©nation ne g√®re pas du tout les index par d√©faut.</font>
elle met juste le second data frame √† la suite du premier, ainsi il y a des index en doublon.

Pour √©viter cela, on peut utiliser l‚Äôargument`ignore_index`¬†, qui √©quivaut √† appliquer une m√©thode`reset_index`¬† : ¬†
```python
pd.concat([df1, df2], ignore_index=True)
```
### jointure

Permet de joindre les informations de 2¬†data frames √† partir d‚Äôune cl√©, une variable commune aux 2¬†data frames. La **cl√©** peut √™tre form√©e d‚Äôune ou plusieurs colonnes

Le fait de rassembler plusieurs jeux de donn√©es diff√©rents est appel√© une¬†**jointure**, en alg√®bre relationnelle.

l‚Äôop√©ration est quasi √©quivalente √† une jointure qu‚Äôon pourrait r√©aliser en SQL
mais les **cl√©s primaires** et **√©trang√®res** ne sont pas explicitement identifi√©es dans un data frame Python.

Il existe deux fa√ßons de faire une jointure entre 2 data frames ¬†`A`¬†et`B`¬† avec Pandas¬†:
- la fonction `merge`
- la m√©thode `merge`
```python
# fonction Pandas :
pd.merge(A, B)
# m√©thode de data frame :
A.merge(B)
```
¬†m√™mes arguments, m√™mes r√©sultats
¬†
**jointure naturelle** :
Par d√©faut, Pandas va chercher les colonnes en commun dans les diff√©rents data frames (celles qui portent le m√™me nom) et va les s√©lectionner comme cl√©s

**Si on sp√©cifie la cl√©**  :

- argument`on`
  La cl√© porte le m√™me nom dans chaque data frame

- arguments`right_on`¬† et ¬†`left_on`
  pr√©cise quelle cl√© on va utiliser dans chaque data frame,¬†droite et  gauche

#### Exemples :

Jointure jointure simple sur une cl√© `id` entre 2 data frames A et B

```python
pd.merge(A, B, on='id')
```

Jointure entre 2 dataframes C (`left`) et A (`right`)
Effectue la jointure sur a cl√©`identifiant` du data frame C
avec la cl√©¬†`id`¬†du data frame A
```python
C.merge(A, left_on='identifiant', right_on='id')
```

Le data frame `left` est le premier renseign√©, donc A, avec la cl√© `id`
Le data frame `right` est B, avec la cl√© `identifiant`

```python
pd.merge(A, B, left_on='id', right_on='identifiant')
```

### Explorez les diff√©rents types de jointure

Avec Pandas, il est indispensable de fixer le type de jointure¬†pour d√©terminer comment traiter les diff√©rentes cl√©s des data frames

Notamment lorsqu‚Äôil y a des soucis de correspondance¬†‚Äì une cl√© pr√©sente dans un data frame mais pas dans l‚Äôautre.

Il existe 4 types de jointures, qui sont toutes focalis√©es sur les diff√©rentes cl√©s¬†:

| interne  | `inner join` |
| -------- | ------------ |
| √† gauche | `left join`  |
| √† droite | `right join` |
| externe  | `outer join` |
- la jointure interne conserve les cl√©s se trouvant dans le premier ET le second data frame 

- la jointure √† droite (ou √† gauche) qui conserve uniquement les cl√©s se trouvant dans le data frame √† droite (ou √† gauche), et compl√®te les informations manquantes par des valeurs manquantes, ou`NaN`¬†;

- la jointure externe qui conserve toutes les cl√©s se trouvant dans le premier OU le second data frame.
 
