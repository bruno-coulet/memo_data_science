{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset Iris depuis une URL\n",
    "url = \"https://raw.githubusercontent.com/jundewu10/Iris-dataset/main/iris.csv\"\n",
    "\n",
    "# Télécharger le CSV avec pandas\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "\n",
    "# Télécharger le contenu brut du CSV\n",
    "import requests\n",
    "response = requests.get(url)\n",
    "raw_data = response.content "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Connaitre l'encodage du fichier source .csv</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "with open(\"source.csv\", rb) as fichier_brut:\n",
    "    encodage = chardet.detect(fichier_brut.read(1000))\n",
    "print(encodage)\n",
    "# # >>> { 'encoding' : 'UTF-8-SIG', 'confidence': 1.0, 'language' : ''}\n",
    "\n",
    "df = pd.read_csv(\"source.csv\", encoding='utf-sig-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Connaitre l'encodage du fichier source binaire</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "# Détecter l'encodage d'un binaire\n",
    "encodage = chardet.detect(raw_data)\n",
    "print(encodage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #c8a043ff; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<h3>Valeurs manquantes</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Récupération des noms de variables vides</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_variables = df.columns[df.isna().all()].tolist()\n",
    "empty_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Remplacement des manquants par zéro, voir librairie Missingno</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 : réassigner directement la colonne\n",
    "df['sepal_length'] = df['sepal_length'].fillna(0)\n",
    "\n",
    "# Option 2 : utiliser fillna sur le DataFrame entier\n",
    "df.fillna({'sepal_length': 0}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Taux de remplissage par variables</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_rate = df.count() / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #c8a043ff; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<h3>Statistiques descriptives</h3>\n",
    "</div>\n",
    "\n",
    "\n",
    "- `s` est une `pandas.Series`\n",
    "- `df` est un `pandas.DataFrame`\n",
    "- `x`, `y` sont des `numpy.ndarray`\n",
    "\n",
    "| Indicateur               | pandas               | numpy                              |\n",
    "| ------------------------ | -------------------- | ---------------------------------- |\n",
    "| Moyenne                  | `s.mean()`           | `np.mean(x)`                       |\n",
    "| Médiane                  | `s.median()`         | `np.median(x)`                     |\n",
    "| Mode                     | `s.mode()`           | — *(pas natif)*                    |\n",
    "| Minimum                  | `s.min()`            | `np.min(x)`                        |\n",
    "| Maximum                  | `s.max()`            | `np.max(x)`                        |\n",
    "| Étendue (max − min)      | `s.max() - s.min()`  | `np.ptp(x)`                        |\n",
    "| Somme                    | `s.sum()`            | `np.sum(x)`                        |\n",
    "| Variance                 | `s.var()`            | `np.var(x)`                        |\n",
    "| Écart-type               | `s.std()`            | `np.std(x)`                        |\n",
    "| Quantile                 | `s.quantile(q)`      | `np.quantile(x, q)`                |\n",
    "| Percentile               | `s.quantile(q)`      | `np.percentile(x, q)`              |\n",
    "| Coefficient de variation | `s.std() / s.mean()` | `np.std(x) / np.mean(x)`           |\n",
    "| Asymétrie (skewness)     | `s.skew()`           | — *(via `scipy.stats.skew`)*       |\n",
    "| Aplatissement (kurtosis) | `s.kurt()`           | — *(via `scipy.stats.kurtosis`)*   |\n",
    "|Rang  |`df[\"Column\"].rank()`  |`np.argsort(array)`|\n",
    "| Covariance               | `s.cov(t)`           | `np.cov(x, y)`                     |\n",
    "| Matrice de covariance    | `df.cov()`           | `np.cov(X, rowvar=False)`          |\n",
    "| Corrélation (Pearson)    | `s.corr(t)`          | `np.corrcoef(x, y)`                |\n",
    "| Matrice de corrélation   | `df.corr()`          | `np.corrcoef(X, rowvar=False)`     |\n",
    "| Comptage (effectif)      | `s.count()`          | `x.size`                           |\n",
    "| Valeurs uniques          | `s.nunique()`        | `np.unique(x).size`                |\n",
    "| Fréquences               | `s.value_counts()`   | `np.unique(x, return_counts=True)` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #c8a043ff; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<h3>Variables catégorielles</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Récupération des variables n'ayant qu'une seule modalité</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna=False force à considérer les valeurs manquantes comme une modalité\n",
    "unique_variables = df.columns[ (df.nunique(dropna=False) == 1 ).values].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "<p>Regroupe les catégories rares</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rare_categorie(df, column, threshold=5, new_label='Other'):\n",
    "    \"\"\"\n",
    "    Pour un DataFrame (df)\n",
    "    la fonction regroupe les catégories rares\n",
    "    fixées par un seuil (threshold) d'une variable catégorielle (column)\n",
    "    sous l'étiquette 'labenew_l'\n",
    "    \"\"\"\n",
    "    # calcul de la fréquence des modalités\n",
    "    frequency = df[column].value_counts()\n",
    "    # identification des catégories rares\n",
    "    rare_categories = frequency[frequency < threshold].index\n",
    "    # remplacement des catégories rares par 'Other'\n",
    "    df[columns] = df[columns].replace(rare_categories, new_label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h4>Tableau de contingence ou tableau croisé</h4>\n",
    "<p>Explore les associations entres 2 variables</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "contengency_table = pd.crosstab(df['column_1'], df['column_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #c8a043ff; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Indice de diversité</h3>\n",
    "    <p>quantifient la répartition et l'équilibre des catégories au sein dune variable ou d'un couple de variables</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h4>Indice de diversité de Berger-Parker</h4>\n",
    "    Proportion de la catégorie la plus importante<br>\n",
    "    Plus il est proche de 0, plus il y a de diversité<br>\n",
    "    Plus il est proche de 1, moins il y a de diversité</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def berger_parker_index(df):\n",
    "    \"\"\"\n",
    "    Calcule l'indice de Berger-Parker pour la variable catégorielle du tableau de contingence (df)\n",
    "    Proportion de la catégorie la plus importante\n",
    "    Plus il est proche de 1, plus la diversité est faible et inversement\n",
    "    \"\"\"\n",
    "    # Normalisation par colonne\n",
    "    proportion = df.div(df.sum(axis=1), axis=0)\n",
    "    # Valeur maximale par ligne\n",
    "    berger_index = proportion.max(axis=1)\n",
    "    # affichage sous )-àforme de DataFrame\n",
    "    return pd.DataFrame(\n",
    "        berger_index, \n",
    "        columns=['Berger-Parker Index']\n",
    "    )\n",
    "\n",
    "# Calcul de l'indice de Berger-Parker\n",
    "berger_parker_index = berger_parker_index(contengency_table)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h4>Indice de diversité de Simpson</h4>\n",
    "    <p>Probabilité que 2 individus sélectionnés au hasard dans une population appartiennent à la même catégorie<br>\n",
    "    Plus il est proche de 0, plus il y a de diversité<br>\n",
    "    Plus il est proche de 1, moins il y a de diversité</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpson_index(df):\n",
    "    \"\"\"\n",
    "    Calcule l'indice de Simpson pour la variable catégorielle du tableau de contingence (df)\n",
    "    Probabilité que deux individus pris au hasard appartiennent à la même catégorie\n",
    "    Plus il est proche de 1, plus la diversité est faible et inversement\n",
    "    \"\"\"\n",
    "    # Normalisation par colonne\n",
    "    proportion = df.div(df.sum(axis=1), axis=0)\n",
    "    # Somme des carrés des proportions par ligne\n",
    "    simpson_index = (proportion ** 2).sum(axis=1)\n",
    "    # affichage sous forme de DataFrame\n",
    "    return pd.DataFrame(\n",
    "        simpson_index, \n",
    "        columns=['Simpson Index']\n",
    "    )\n",
    "# Calcul de l'indice de Simpson\n",
    "simpson_index = simpson_index(contengency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h4>Indice de diversité de Shannon-Weaver</h4>\n",
    "    <p>Chaque proportion est multipuié par son logarithme<br>\n",
    "    Donne plus de poids au catégories moins communes<br>\n",
    "    vaut 0 s'il n'y a qu'une catégorie<br>\n",
    "    plus il y a de catégories, plus cette indice peut être élevé</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_index(df):\n",
    "    \"\"\"\n",
    "    Calcule l'indice de Shannon pour la variable catégorielle du tableau de contingence (df)\n",
    "    Mesure de l'incertitude associée au choix d'une catégorie au hasard\n",
    "    Plus il est élevé, plus la diversité est grande\n",
    "    \"\"\"\n",
    "    # Normalisation par colonne\n",
    "    proportion = df.div(df.sum(axis=1), axis=0)\n",
    "    # Calcul de l'indice de Shannon\n",
    "    shannon_index = - (proportion * np.log(proportion + 1e-9)).sum(axis=1)\n",
    "    # affichage sous forme de DataFrame\n",
    "    return pd.DataFrame(\n",
    "        shannon_index, \n",
    "        columns=['Shannon Index']\n",
    "    )\n",
    "# Calcul de l'indice de Shannon\n",
    "shannon_index = shannon_index(contengency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Fonctions</h3>\n",
    "<p>détection des outliers</p>\n",
    "<ul><li>méthode des quartiles (écart interquartiles)</li><li>méthode des z-score</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(data, factor=1.5):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    return (data < lower_bound) | (data > upper_bound)\n",
    "\n",
    "\n",
    "def detect_outliers_z_score(data, threshold=3):\n",
    "    z_scores = (data - data.mean()) / data.std()\n",
    "    return np.abs(z_scores) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de données de test\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "# Ajout d'outliers\n",
    "data[0] = 10\n",
    "data[1] = -10\n",
    "\n",
    "# Détection des outliers avec la méthode des quartiles\n",
    "outliers_iqr = detect_outliers_iqr(pd.Series(data))\n",
    "print(\"Outliers détectés par la méthode des quartiles:\")\n",
    "print(pd.Series(data)[outliers_iqr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Local Outlier Factor</h3>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# matrice de données avec 100 échantillons et 2 variables\n",
    "# random.randn génère des échantillons à partir d'une distribution normale entre 0 et 1\n",
    "X = 0.6 * np.random.randn(100, 2)\n",
    "\n",
    "# Insertion de quelques outliers\n",
    "# random.uniform génère des valeurs aléatoires uniformément distribuées entre low et high\n",
    "X_outliers = np.random.uniform(low=-5, high=5, size=(10, 2))\n",
    "\n",
    "# Compilation verticale des données normales et des outliers\n",
    "X = np.vstack([X, X_outliers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrainement du modèle LOF\n",
    "clf = LocalOutlierFactor(n_neighbors=10)\n",
    "\n",
    "# Entrainement et prédiction\n",
    "# Définin chaque point comme normal ou pas\n",
    "# -1 pour les outliers et 1 pour les points normaux\n",
    "y_pred = clf.fit_predict(X)\n",
    "\n",
    "# Création d'un masque pour les outliers\n",
    "outliers_mask = y_pred == -1\n",
    "\n",
    "# outliers en bleu\n",
    "plt.scatter(X[outliers_mask, 0], X[outliers_mask, 1], color='b', label='Outliers')\n",
    "# points normaux en rouge\n",
    "plt.scatter(X[~outliers_mask, 0], X[~outliers_mask, 1], color='r', label='Normal points')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Changement de la distribution</h3>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation logarithmique\n",
    "df['variable_log'] = np.log(['Variable'])\n",
    "\n",
    "# Transformation de la racine carrée\n",
    "df['variable_sqrt'] = np.sqrt(df['Variable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Imputation Pandas</h3>\n",
    "<ul>\n",
    "<li>modale</li>\n",
    "<li>médiane</li>\n",
    "<li>moyenne</li>\n",
    "</ul>\n",
    "<p>Selon le taux de valeurs manquante,<br>l'imputation par la moyenne augmente le nombre d'outliers</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplir les valeurs manquantes avec la modalité la plus fréquente\n",
    "# précise l'indicece [0] au cas ou il y a plusieurs modalités\n",
    "df['variable'] = df['Variable'].fillna(df['Variable'].mode()[0])\n",
    "\n",
    "# Imputation par la moyenne avec pandas\n",
    "df['variable'] = df['Variable'].fillna(df['Variable'].mean())\n",
    "\n",
    "# Imputation par la m&diane avec pandas\n",
    "df['variable'] = df['Variable'].fillna(df['Variable'].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Imputation Scikit-learn</h3>\n",
    "<ul>\n",
    "<li>modale</li>\n",
    "<li>médiane</li>\n",
    "<li>moyenne</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
    "df['variable'] = imputer_mode.fit_transform(df[['Variable']])\n",
    "\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "df['variable'] = imputer_mean.fit_transform(df[['Variable']])\n",
    "\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "df['variable'] = imputer_median.fit_transform(df[['Variable']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Imputation par regression</h3>\n",
    "<p>\n",
    "Pour une variable cible Y contenant des valeurs manquantes :\n",
    "\n",
    "Séparer les lignes avec Y connu et Y manquant.\n",
    "\n",
    "Entraîner un modèle de régression Y ~ X sur les lignes complètes.\n",
    "\n",
    "Prédire les valeurs manquantes à partir des autres variables.\n",
    "\n",
    "Remplacer les NaN par ces prédictions.\n",
    "\n",
    "C’est une imputation plus intelligente que mean/median/mode.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "imputer = IterativeImputer(estimator=RandomForestRegressor(), max_iter=10)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Exemple : variables numériques et catégorielles\n",
    "numerical_cols = ['age', 'income', 'Variable']     # Variable à imputer\n",
    "categorical_cols = ['genre', 'ville']\n",
    "\n",
    "# Préprocesseur\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", IterativeImputer(estimator=RandomForestRegressor(), max_iter=10), numerical_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Entraînement du pipeline\n",
    "pipeline.fit(df[numerical_cols + categorical_cols], df['Variable'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "cols_with_missing = ['Variable']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[cols_with_missing] = imputer.fit_transform(df[cols_with_missing])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background-color: #439cc8; \n",
    "    color: #fff; \n",
    "    font-size: 16px; \n",
    "    font-style: italic; \n",
    "    padding: 10px 15px; \n",
    "    margin-bottom: 15px; \n",
    "    border-radius: 8px;\">\n",
    "    <h3>Bibliothèque d'Imputation</h3>\n",
    "<p>\n",
    "Fancyimpute\n",
    "\n",
    "impyute\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
